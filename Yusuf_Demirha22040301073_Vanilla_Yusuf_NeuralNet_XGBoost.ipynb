{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b975781-b976-4308-b5f7-cfecb17f4efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'merged_all_months.csv',\n",
       " 'Yusuf_NeuralNet_XGBoost.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6d8b63-3836-47b8-9b69-71549347c06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>route_code</th>\n",
       "      <th>stop_code</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>district</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>mean_passenger_by_route_hour</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>MESCIDI SELAM-ARNAVUTKOY-ISTANBUL HAVA LIMANI</td>\n",
       "      <td>OTOYOL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.782609</td>\n",
       "      <td>bilinmeyen_ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>MECIDIYEKOY-ISTANBUL HAVALIMANI</td>\n",
       "      <td>OTOYOL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>bilinmeyen_ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>KOC UNV. RUMELIFENER KAMPUSU - TAKSIM</td>\n",
       "      <td>OTOYOL</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>bilinmeyen_ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>HACI OSMAN METRO -  RUMELI FENERI</td>\n",
       "      <td>OTOYOL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>bilinmeyen_ay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>USKUDAR-GUZELTEPE-UMRANIYE DEVLET HASTANESI</td>\n",
       "      <td>OTOYOL</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BAKIRKOY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.258065</td>\n",
       "      <td>bilinmeyen_ay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour                                     route_code stop_code  \\\n",
       "0  2024-08-01     0  MESCIDI SELAM-ARNAVUTKOY-ISTANBUL HAVA LIMANI    OTOYOL   \n",
       "1  2024-08-01     0                MECIDIYEKOY-ISTANBUL HAVALIMANI    OTOYOL   \n",
       "2  2024-08-01     0          KOC UNV. RUMELIFENER KAMPUSU - TAKSIM    OTOYOL   \n",
       "3  2024-08-01     0              HACI OSMAN METRO -  RUMELI FENERI    OTOYOL   \n",
       "4  2024-08-01     0    USKUDAR-GUZELTEPE-UMRANIYE DEVLET HASTANESI    OTOYOL   \n",
       "\n",
       "   passenger_count  vehicle_type  district  is_outlier  is_peak_hour  \\\n",
       "0                1             1  ATASEHIR           0             0   \n",
       "1                1             1  ATASEHIR           0             0   \n",
       "2                3             1  ATASEHIR           0             0   \n",
       "3                1             1  ATASEHIR           0             0   \n",
       "4                3             1  BAKIRKOY           0             0   \n",
       "\n",
       "   day_of_week  is_weekend  mean_passenger_by_route_hour          month  \n",
       "0            3           0                      1.782609  bilinmeyen_ay  \n",
       "1            3           0                      1.200000  bilinmeyen_ay  \n",
       "2            3           0                      1.666667  bilinmeyen_ay  \n",
       "3            3           0                      1.538462  bilinmeyen_ay  \n",
       "4            3           0                      4.258065  bilinmeyen_ay  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"merged_all_months.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3361703-5658-4baa-a11c-8a8f3cadc9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>route_code</th>\n",
       "      <th>district</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>mean_passenger_by_route_hour</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MESCIDI SELAM-ARNAVUTKOY-ISTANBUL HAVA LIMANI</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.782609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MECIDIYEKOY-ISTANBUL HAVALIMANI</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>KOC UNV. RUMELIFENER KAMPUSU - TAKSIM</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>HACI OSMAN METRO -  RUMELI FENERI</td>\n",
       "      <td>ATASEHIR</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>USKUDAR-GUZELTEPE-UMRANIYE DEVLET HASTANESI</td>\n",
       "      <td>BAKIRKOY</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.258065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour                                     route_code  district  day_of_week  \\\n",
       "0     0  MESCIDI SELAM-ARNAVUTKOY-ISTANBUL HAVA LIMANI  ATASEHIR            3   \n",
       "1     0                MECIDIYEKOY-ISTANBUL HAVALIMANI  ATASEHIR            3   \n",
       "2     0          KOC UNV. RUMELIFENER KAMPUSU - TAKSIM  ATASEHIR            3   \n",
       "3     0              HACI OSMAN METRO -  RUMELI FENERI  ATASEHIR            3   \n",
       "4     0    USKUDAR-GUZELTEPE-UMRANIYE DEVLET HASTANESI  BAKIRKOY            3   \n",
       "\n",
       "   is_weekend  is_peak_hour  mean_passenger_by_route_hour  vehicle_type  \n",
       "0           0             0                      1.782609             1  \n",
       "1           0             0                      1.200000             1  \n",
       "2           0             0                      1.666667             1  \n",
       "3           0             0                      1.538462             1  \n",
       "4           0             0                      4.258065             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Kullanacağımız feature seti\n",
    "features = [\n",
    "    'hour',\n",
    "    'route_code',\n",
    "    'district',\n",
    "    'day_of_week',\n",
    "    'is_weekend',\n",
    "    'is_peak_hour',\n",
    "    'mean_passenger_by_route_hour'\n",
    "]\n",
    "\n",
    "target = 'vehicle_type'   # Yusuf için sınıflandırma hedefi\n",
    "\n",
    "# Sadece gerekli kolonlar\n",
    "df = df[features + [target]]\n",
    "\n",
    "# Eksik veri varsa temizle\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5689831-8a43-4ca4-bc44-d2ff4e9d0b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2374022, 7), (593506, 7))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d423b37-12b1-40fa-a90d-2f0f4c0f27cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'KADIKOY-ESENKENT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:235\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:174\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    173\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device\u001b[38;5;241m=\u001b[39mdevice(values))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:167\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'KADIKOY-ESENKENT'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m le_district \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m      6\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_route\u001b[38;5;241m.\u001b[39mfit_transform(X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_route\u001b[38;5;241m.\u001b[39mtransform(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_district\u001b[38;5;241m.\u001b[39mfit_transform(X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_district\u001b[38;5;241m.\u001b[39mtransform(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray([])\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:237\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'KADIKOY-ESENKENT'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_route = LabelEncoder()\n",
    "le_district = LabelEncoder()\n",
    "\n",
    "X_train['route_code'] = le_route.fit_transform(X_train['route_code'])\n",
    "X_test['route_code'] = le_route.transform(X_test['route_code'])\n",
    "\n",
    "X_train['district'] = le_district.fit_transform(X_train['district'])\n",
    "X_test['district'] = le_district.transform(X_test['district'])\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fadaa82-e89b-4f81-b87b-df091c81a853",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:183\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    181\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[0;32m--> 183\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(uniques_set)\n\u001b[1;32m    184\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m le_district \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Encode\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_route\u001b[38;5;241m.\u001b[39mfit_transform(combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute_code\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m le_district\u001b[38;5;241m.\u001b[39mfit_transform(combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Tekrar ayır\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:111\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    Encoded labels.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m _unique(y, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:52\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_python(\n\u001b[1;32m     53\u001b[0m         values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[1;32m     57\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_encode.py:188\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Train-Test'i birleştir\n",
    "combined = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "# LabelEncoder nesneleri\n",
    "le_route = LabelEncoder()\n",
    "le_district = LabelEncoder()\n",
    "\n",
    "# Encode\n",
    "combined['route_code'] = le_route.fit_transform(combined['route_code'])\n",
    "combined['district'] = le_district.fit_transform(combined['district'])\n",
    "\n",
    "# Tekrar ayır\n",
    "X_train = combined.iloc[:len(X_train)]\n",
    "X_test = combined.iloc[len(X_train):]\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677db2fa-9cbd-489f-8cd8-151689aa9508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    MESCIDI SELAM-ARNAVUTKOY-ISTANBUL HAVA LIMANI\n",
       " 1                  MECIDIYEKOY-ISTANBUL HAVALIMANI\n",
       " 2            KOC UNV. RUMELIFENER KAMPUSU - TAKSIM\n",
       " 3                HACI OSMAN METRO -  RUMELI FENERI\n",
       " 4      USKUDAR-GUZELTEPE-UMRANIYE DEVLET HASTANESI\n",
       " Name: route_code, dtype: object,\n",
       " array([<class 'str'>], dtype=object))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['route_code'].head(), df['route_code'].apply(type).unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228a0bae-13f8-4c95-ba0a-85b803d6ca39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    ATASEHIR\n",
       " 1    ATASEHIR\n",
       " 2    ATASEHIR\n",
       " 3    ATASEHIR\n",
       " 4    BAKIRKOY\n",
       " Name: district, dtype: object,\n",
       " array([<class 'str'>], dtype=object))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['district'].head(), df['district'].apply(type).unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f0260c-e481-4c7c-967d-9d24df08e0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>route_code</th>\n",
       "      <th>district</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>mean_passenger_by_route_hour</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.782609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>803</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.258065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  route_code  district  day_of_week  is_weekend  is_peak_hour  \\\n",
       "0     0         586         2            3           0             0   \n",
       "1     0         580         2            3           0             0   \n",
       "2     0         535         2            3           0             0   \n",
       "3     0         344         2            3           0             0   \n",
       "4     0         803         6            3           0             0   \n",
       "\n",
       "   mean_passenger_by_route_hour  vehicle_type  \n",
       "0                      1.782609             1  \n",
       "1                      1.200000             1  \n",
       "2                      1.666667             1  \n",
       "3                      1.538462             1  \n",
       "4                      4.258065             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_route = LabelEncoder()\n",
    "le_district = LabelEncoder()\n",
    "\n",
    "df['route_code'] = le_route.fit_transform(df['route_code'])\n",
    "df['district'] = le_district.fit_transform(df['district'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e86b03-3b36-42cb-a357-b5f074c9a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   hour  route_code  district  day_of_week  is_weekend  is_peak_hour  \\\n",
       " 0     0         586         2            3           0             0   \n",
       " 1     0         580         2            3           0             0   \n",
       " 2     0         535         2            3           0             0   \n",
       " 3     0         344         2            3           0             0   \n",
       " 4     0         803         6            3           0             0   \n",
       " \n",
       "    mean_passenger_by_route_hour  \n",
       " 0                      1.782609  \n",
       " 1                      1.200000  \n",
       " 2                      1.666667  \n",
       " 3                      1.538462  \n",
       " 4                      4.258065  ,\n",
       " 0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: vehicle_type, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('vehicle_type', axis=1)\n",
    "y = df['vehicle_type']\n",
    "\n",
    "X.head(), y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18470075-9eab-46e2-b72d-f548de3d9b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2374022, 7), (593506, 7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6032f8cc-a59d-4e52-91a7-454c03cfee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.55237529, -1.07439611, -0.85198211, -0.97234228, -0.57578571,\n",
       "         -1.0124361 , -0.60145586],\n",
       "        [-0.26022339, -0.42111692,  1.42604048, -1.48769102, -0.57578571,\n",
       "         -1.0124361 , -0.71185476],\n",
       "        [-0.62274312, -1.66794692, -0.85198211,  0.57370396, -0.57578571,\n",
       "          0.98771666, -0.03472516],\n",
       "        [ 0.64607595,  0.0492441 , -0.85198211,  0.05835522, -0.57578571,\n",
       "          0.98771666,  0.12246125],\n",
       "        [ 1.55237529, -0.82428351, -0.85198211,  1.60440145,  1.73675723,\n",
       "         -1.0124361 , -0.20681154]]),\n",
       " array([[-1.34778259,  1.62084719,  1.42604048, -0.45699353, -0.57578571,\n",
       "         -1.0124361 , -0.81083308],\n",
       "        [ 0.46481608, -0.122475  , -0.85198211,  1.08905271,  1.73675723,\n",
       "          0.98771666,  0.96062505],\n",
       "        [-0.98526286, -0.89521096,  1.42604048, -0.97234228, -0.57578571,\n",
       "          0.98771666, -0.14316868],\n",
       "        [-0.44148325,  0.29189066, -0.85198211,  1.08905271,  1.73675723,\n",
       "         -1.0124361 ,  1.80730311],\n",
       "        [-1.34778259,  1.13555407,  0.98795921, -0.45699353, -0.57578571,\n",
       "         -1.0124361 , -0.30129972]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Scaling ===\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Sadece X_train'e fit et → X_test'e sadece transform uygulanır\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled[:5], X_test_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c47e02-ec46-46a5-a8d4-3c2ee4a446ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32),\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    max_iter=20,\n",
    "                    random_state=42)\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_mlp = mlp.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1d6645-a21e-4986-b186-0b0e2828577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.976603437875944\n",
      "MLP Precision: 0.9248318425066606\n",
      "MLP Recall: 0.8191472901524435\n",
      "MLP F1: 0.8652183514615129\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      1.00      0.99    543946\n",
      "           2       0.88      0.65      0.75     19119\n",
      "           3       0.91      0.81      0.85     30441\n",
      "\n",
      "    accuracy                           0.98    593506\n",
      "   macro avg       0.92      0.82      0.87    593506\n",
      "weighted avg       0.98      0.98      0.98    593506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"MLP Precision:\", precision_score(y_test, y_pred_mlp, average='macro'))\n",
    "print(\"MLP Recall:\", recall_score(y_test, y_pred_mlp, average='macro'))\n",
    "print(\"MLP F1:\", f1_score(y_test, y_pred_mlp, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44445ed4-2c83-452b-9561-69dd052b7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8143aaa-196a-48dd-ac30-811c8d563159",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [1 2 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m      2\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m xgb\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[1;32m     12\u001b[0m y_pred_xgb \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1490\u001b[0m ):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1494\u001b[0m     )\n\u001b[1;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [1 2 3]"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22018b9d-4582-496f-ac50-19598f14ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle_type 1-2-3 → 0-1-2 olarak yeniden etiketleniyor\n",
    "df['vehicle_type'] = df['vehicle_type'] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b750e19f-1fd9-4b77-a05f-fa77ed32c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['vehicle_type'])\n",
    "y = df['vehicle_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a74cc27-1d71-4c6c-b230-76afd8497da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ff76c7-e7a3-456e-a8b7-64540ee2ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "233c1d93-114b-4033-b4b7-4753f8112fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f99ec32e-77c4-43de-82a7-a8e28311bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9932856618130229\n",
      "XGBoost Precision: 0.972440243902965\n",
      "XGBoost Recall: 0.9479630668524629\n",
      "XGBoost F1: 0.9597886052077568\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    543946\n",
      "           1       0.96      0.89      0.92     19119\n",
      "           2       0.96      0.95      0.96     30441\n",
      "\n",
      "    accuracy                           0.99    593506\n",
      "   macro avg       0.97      0.95      0.96    593506\n",
      "weighted avg       0.99      0.99      0.99    593506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Precision:\", precision_score(y_test, y_pred_xgb, average='macro'))\n",
    "print(\"XGBoost Recall:\", recall_score(y_test, y_pred_xgb, average='macro'))\n",
    "print(\"XGBoost F1:\", f1_score(y_test, y_pred_xgb, average='macro'))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3387b24-2199-4265-937f-1d2d456ba038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP (Neural Network)</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.9248</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>0.8652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.9597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision  Recall  F1-score\n",
       "0  MLP (Neural Network)    0.9766     0.9248  0.8191    0.8652\n",
       "1               XGBoost    0.9933     0.9724  0.9479    0.9597"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    [\"MLP (Neural Network)\", 0.9766, 0.9248, 0.8191, 0.8652],\n",
    "    [\"XGBoost\", 0.9933, 0.9724, 0.9479, 0.9597],\n",
    "], columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"])\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa380533-6679-4674-87c6-7d1952da95ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
